<!doctype html><html class="no-js" lang="en"><head><meta charset="utf-8"><meta name="author" content="Geshan Manandhar"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="Learn how to scrape any webpage with or without Javascript rendering using Node.js. This tutorial will be the only guide you need to start web scraping with Node.js successfully."><meta name="keywords" content="web scraping node.js, node.js web scraping, node web scraping, web scapring node"><meta name="p:domain_verify" content="e654c68562abebfa25c291f59d7d00e8"><meta property="og:type" content="website"><meta property="og:url" content="https://geshan.com.np/blog/2021/09/web-scraping-nodejs/"><meta property="og:title" content="The final guide to web scraping with Node.js"><meta property="og:description" content="Learn how to scrape any webpage with or without Javascript rendering using Node.js. This tutorial will be the only guide you need to start web scraping with Node.js successfully."><meta property="og:site_name" content="Geshan&#39;s Blog"><meta property="og:image" content="https://geshan.com.np/images/nodejs-web-scraping/01nodejs-web-scraping.jpg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:widgets:new-embed-design" content="on"><meta name="twitter:site" content="@geshan"><meta name="twitter:creator" content="@geshan"><meta name="twitter:title" content="The final guide to web scraping with Node.js"><meta name="twitter:description" content="Learn how to scrape any webpage with or without Javascript rendering using Node.js. This tutorial will be the only guide you need to start web scraping with Node.js successfully."><meta name="twitter:image:src" content="https://geshan.com.np/images/nodejs-web-scraping/01nodejs-web-scraping.jpg"><link rel="canonical" href="https://geshan.com.np/blog/2021/09/web-scraping-nodejs/"><meta property="fb:pages" content="30717799226"><meta property="fb:app_id" content="106030259434380"><meta name="monetization" content="$ilp.uphold.com/aKHWpqhphm9f"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicons/favicon-16x16.png"><link href="/atom.xml" rel="alternate" title="Geshan&#39;s Blog" type="application/atom+xml"><title>The final guide to web scraping with Node.js</title><link rel="preconnect" href="/" crossorigin><link rel="preload" href="/css/fonts.css" as="style"><link rel="preload" href="/fonts/source-sans-4/source-serif-4-latin-400-normal.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="/fonts/source-sans-4/source-serif-4-latin-500-normal.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="/fonts/source-sans-pro/source-sans-pro-latin-400-normal.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="/css/fonts.css"><link rel="stylesheet" href="/css/tw-006.css"><link rel="alternate" href="/atom.xml" type="application/atom+xml" title="Geshan&#39;s Blog"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-P3NXCVQEPE"></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-P3NXCVQEPE');</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWT2D9T');</script><script src="https://cdn.jsdelivr.net/npm/@statsig/js-client@3/build/statsig-js-client+session-replay+web-analytics.min.js?apikey=client-rYO7rX8WSUyyLg9pKJwymLxM71tCE0CKgxgtUj4akzK"></script><link rel="manifest" href="/manifest.json"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="application-name" content="Geshan.com.np"><meta name="apple-mobile-web-app-title" content="Geshan.com.np"><meta name="msapplication-starturl" content="/index.html"><meta name="theme-color" content="#6947E7"><script>if ("serviceWorker" in navigator) {
    navigator.serviceWorker.register("/sw.js").then(function(registration) {
        console.log('ServiceWorker registration successful with scope: ', registration.scope);
    }, function(err) {
        console.log('ServiceWorker registration failed: ', err);
    });
  }</script></head><body class="overflow-x-hidden font-ui flex flex-col min-h-screen"><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWT2D9T" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><header role="banner"><div><nav class="bg-white" role="navigation"><div class="w-full md:max-w-6xl mx-auto py-4 px-4"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><a href="/" class="flex items-center"><img class="h-12 w-12" src="/images/theme/new_logo.svg" alt="Geshan G"></a></div><div class="flex items-center gap-12"><div class="hidden sm:flex items-center gap-12"><a href="/posts/1/" class="uppercase text-base font-ui font-medium text-gray hover:text-midgrey transition-colors" aria-current="page">Posts </a><a href="/about/" class="uppercase text-base font-ui font-medium text-gray hover:text-midgrey transition-colors" aria-current="page">About Me </a><a href="https://newsletter.geshan.com.np/" class="uppercase text-base font-ui font-medium text-gray hover:text-midgrey transition-colors" aria-current="page">Newsletter</a></div><form class="search flex items-center" action="https://www.google.com/search" method="GET"><input type="hidden" name="sitesearch" value="geshan.com.np"><div class="relative"><input class="bg-gray-100 border border-neutralGray rounded-lg py-2 pl-10 pr-4 font-body text-sm focus:outline-none focus:ring-2 focus:ring-avocado focus:border-transparent w-40" type="text" name="q" placeholder="Search" label="search"> <svg class="absolute left-3 top-1/2 transform -translate-y-1/2 w-4 h-4 text-neutralGray" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"/></svg></div></form><button type="button" class="sm:hidden inline-flex items-center justify-center p-2 rounded-md text-black focus:outline-none focus:ring-2 focus:ring-inset focus:ring-avocado" onclick="mobileView()" aria-controls="mobile-menu" aria-expanded="false"><span class="sr-only">Open main menu</span> <svg class="w-6 h-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewbox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg></button></div></div></div><div class="mobile-menu fixed inset-0 z-40 hidden sm:hidden bg-black bg-opacity-40" role="dialog" aria-modal="true"><div class="absolute inset-0" onclick="mobileView()" aria-hidden="true"></div><div class="mobile-menu-panel relative ml-auto flex h-full w-10/12 max-w-sm flex-col justify-start bg-white shadow-xl"><div class="flex items-center justify-between px-4 py-4 border-b border-gray-200"><div class="flex items-center gap-3"><img class="h-8 w-8" src="/images/theme/new_logo.svg" alt="Geshan G"> <span class="text-lg font-semibold text-textColor font-body">Geshan's Blog</span></div><button type="button" class="inline-flex items-center justify-center rounded-full p-2 text-gray-700 hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-avocado" onclick="mobileView()" aria-label="Close main menu"><svg class="h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/></svg></button></div><nav class="overflow-y-auto px-4 py-6 space-y-2"><a href="/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">Home </a><a href="/posts/1/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">Posts </a><a href="/about/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">About Me </a><a href="https://newsletter.geshan.com.np/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">Newsletter</a></nav><div class="px 4 py-4 border-t border-gray-200"><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="rounded-lg bg-darkAvocado px-4 py-2 text-base font-regular font-body text-white hover:bg-avocado hover:text-black transition-colors w-2/3 mx-auto ml-4">Connect on LinkedIn</a></div></div></div></nav></div></header><main id="wrap" role="main" class="flex-grow md:px-0"><div id="content"><div class="row"><div><script type="application/ld+json">{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Geshan&#39;s Blog",
    "alternativeHeadline": "The final guide to web scraping with Node.js",
    "image": "https://geshan.com.np/images/nodejs-web-scraping/01nodejs-web-scraping.jpg",
    "editor": "Geshan Manandhar",
    "genre": "Software Engineering",
    "keywords": "web scraping node.js, node.js web scraping, node web scraping, web scapring node",
    "url": "https://geshan.com.np/blog/2021/09/web-scraping-nodejs/",
    "datePublished": "2021-09-18",
    "dateCreated": "2021-09-18",
    "dateModified": "2021-09-18",
    "description": "Learn how to scrape any webpage with or without Javascript rendering using Node.js. This tutorial will be the only guide you need to start web scraping with Node.js successfully.",
    "articleBody": "Web scraping is the process of extracting data from a website in an automated way and Node.js can be used for web scraping. Even though other languages and frameworks are more popular for web scraping, Node.js can be utilized well to do the job too. In this post, we will learn how to do web scraping with Node.js for websites that don’t need and need Javascript to load. Let’s get started!Table of contents #Table of contentsWeb scraping the dos and don’tsPrerequisitesWeb scraping with Node.js the simple exampleAxios and Cheerio for Node.js web scrapingNode.js web scraping rendering JavaScriptPuppeteer for web scrapingConclusionWeb scraping the dos and don’ts #Web scraping can be very advantageous to aggregate data from multiple sources or even track what one’s competitor is doing. But, it can have its own legal and technical issues too. A general technical problem being too many requests coming from the same IP in a very short amount of time as the traffic is coming from a machine than a browser or a human.Even when scraping a website it is best to respect the robots.txt file and be nice to the maintainers of the website. Don’t be that person who would send 50 requests per second to a website from the same IP address adding unnecessary load to the servers and making the website slow for other users. Next up, we will look at an example of a simple web scraper with Node.js.Python’s Scrapy framework might be one of the best tools to do web scraping but if you just know Javascript you can build a pretty decent web scraper with Node.js too.Prerequisites #Before we dive into the code, below are some prerequisitesYou have Node.js (preferably the latest LTS version) and NPM node running on your machineInstaling NPM modules is known to youAny prior knowledge or experience of web scraping, CSS selectors, or Xpath will be helpful.Let’s get started with some code now.Web scraping with Node.js the simple example #Websites and webpages can basically be divided into two broad categories. The first segment doesn’t need JavaScript rendering to show most of the content of the webpage, and the second needs Javascript execution to render any of its content. The first group of websites is much easier to scrape because the HTML rendered is almost the same for a browser that can execute Javascript compared to a bot that cannot execute JavaScript.The second set of websites are mainly the Single Page Applications (SPA) that are built with JavaScript framework/libraries like React which need JavaScript execution to show any relevant content. We will see an example later for this class of websites. For now, we will dive into an example that doesn’t need any Javascript execution to get the meaningful contents of the website. For this simple example, we will use Axios and Cheerio to scrape a property listing website called Domain.com,au to check how many rental properties are listed for a given postal code.You can use Bright data to scarpe data from multiple sources. It also has proxy to make web scraping even more easier.Axios and Cheerio for Node.js web scraping #Prior to writing some code to scrape out information. It is best we analyze some patterns that will make our work easier. There are two main things to consider while scraping content, they are the URL and the structure of the page(s) you want to scrape the information out of. URLs have patten, in our example, if you search for rental properties on Domain the URL with postcode looks like:  some code  so 2000 is the postcode part that can be changed to any valid postal code in Australia and it will work.Similarly, when we inspect the page and look for the part we need that is the no. of properties in that postcode. It is available in a “strong” tag inside the “h1” tag. It is easy to see in the inspector of your browser of choice, I am using chrome below:Here CSS selectors are your best friend, XPATH is another powerful option but generally, I prefer CSS selectors. Below is a quick look at the innerText property of ‘h1&amp;gt;strong’ which gives out the text we are after:Now as we know what to target for in the webpage, below is a quick example of getting the number of properties open for rent in a given postcode of Australia pulled in from Domain.com.au rental listing page using Axios and Cheerio:const axios = require(&#39;axios&#39;);const cheerio = require(&#39;cheerio&#39;);(async () =&gt; {  const args = process.argv.slice(2);  const postCode = args[0] || 2000;  const url = `https://www.domain.com.au/rent/?postcode=${postCode}&amp;amp;excludedeposittaken=1`;  try {    const response = await axios.get(url);    const $ = cheerio.load(response.data);    const noOfProperties = $(&#39;h1&gt;strong&#39;).text();    console.log(`${noOfProperties} are open for rent in ${postCode} postcode of Australia on Domain`);  } catch (e) {    console.error(`Error while fetching rental properties for ${postCode} - ${e.message}`);  }})();You can install axios and cheerio with  some code . For this guide, we will use puppeteer to keep things simple.To scrape the job titles on the first page of Workable we will use the following code:const puppeteer = require(&#39;puppeteer&#39;);(async () =&gt; {  try {    const browser = await puppeteer.launch();    const page = await browser.newPage();    const navigationPromise = page.waitForNavigation();    await page.goto(&#39;https://jobs.workable.com/&#39;);    await page.setViewport({ width: 1440, height: 744 });    await navigationPromise;    await page.waitForSelector(&#39;ul li h3 a&#39;);    let jobTitles = await page.$$eval(&#39;ul li h3 a&#39;, titles =&gt; {      return titles.map(title =&gt; title.innerText);    });    console.log(`Job Titles on first page of Workable are: ${jobTitles.join(&#39;, &#39;)}`);    await browser.close();  } catch (e) {    console.log(`Error while fetching workable job titles ${e.message}`);  }})();The code has been partially generated with the Headless Recorder Google Chrome Plugin, you can view its code on GitHub too if you are interested.The code at first includes puppeteer. Then in the IIFE async function similar to the above example, starts the browser and open a new tab. After that, it goes to  some code  array. After that, it logs all the scraped job titles and then closes the browser. We can also use other Node.js logging libraries in place of console.log.This is how it looks when you run it:If the code is run with docker it will need a different way to start the browser. For the above example, I am running it on a Mac. The above code is available as a pull request for your reference. We could have possibly taken the whole HTML rendered after executing the JavaScript and put it into Cheerio to parse it but the above method works too.All the working code is available as a Github repository for your reference. We can also use Node.js with Docker to make the code run seamlessly in multiple operating systems and environments.In addition to scraping just one page, we could get all the links and loop through (or even better promise.all) the pages but at that point, it would be a full-on spider than just web page scraping.Another alternative to Puppeteer is Playwright. It is similar to puppeteer and has a similar API, the advantage is it supports multiple browsers like Firefox and Safari. The headless recorder plugin can generate a good starting script for both Puppeteer and Playwright so you can get a very good starting point if you are not well versed in writing such automation scripts. If you want to learn web scraping with Python, here is the perfect guide for you.Conclusion #We saw how to scrape web pages with Node.js for both types of web pages that don’t require JavaScipt to render meaningful HTML and that requires JavaScript. Using your browser’s inspect tool and some URL pattern matching will surely help you scraper web pages much better.",
    "author": { "@type": "Person", "name": "Geshan Manandhar" },
    "publisher": {
      "@type": "Organization",
      "name": "Geshan Manandhar",
      "logo": { "@type": "ImageObject", "url": "https://geshan.com.np/images/favicons/favicon-32x32.png" }
    },
    "mainEntityOfPage": { "@type": "WebPage", "@id": "https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" }
  }</script><div class="progress-bar"></div><div class="max-w-6xl py-3 mx-auto grid-cols-12 grid gap-15 px-4 md:px-0 mb-20"><div class="col-span-12"><article class="md:w-full mx-auto"><header class="page-header text-center"><h1 class="font-semibold font-heading text-gray text-center mb-6 tracking-[-0.01em] leading-[105%] md:leading-[105%]">The final guide to web scraping with Node.js</h1><div class="flex items-center justify-between gap-3 md:gap-4 flex-wrap md:flex-nowrap py-2 border-y border-lightbg mt-4"><div class="flex items-center justify-start md:gap-4 gap-2 flex-wrap w-2/3"><div class="flex justify-start items-center gap-3 md:gap-4"><img src="/images/favicons/favicon-32x32-pp.png" alt="Geshan Manandhar" class="w-10 h-10 rounded-full object-cover flex-shrink-0"> <span class="text-gray font-medium font-ui text-md md:text-xl uppercase tracking-wide text-start">Geshan Manandhar</span></div><time datetime="2021-09-18" data-updated="true"><time class="entry-date" datetime="2021-09-18"><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">18-Sep-2021 </span></time></time><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">12 MIN READ</span></div><button type="button" id="share-button" class="flex items-center justify-center w-8 h-8 md:w-9 md:h-9 rounded text-lightGray hover:border-gray-400 hover:bg-gray-50 transition-colors flex-shrink-0" aria-label="Share this post" onclick="toggleShareIcons(); ga('send', 'event', 'share', 'clickShareOnPost');"><img src="/images/shareIcon.svg" alt="Share this post" class="w-6 h-6"></button></div><div id="share-icons-container" class="share-icons print:hidden hidden" aria-label="Share this post"><div class="flex items-center justify-center gap-3"><span class="share-icons"><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on LinkedIn" onclick="ga('send', 'event', 'share', 'clickShareOnLinkedIn');"><span id="linkedin-share" class="text-[#0077B5]"><img src="/images/social-icons/linkedin.svg" alt="LinkedIn" class="sharing-common"> </span></a><a href="http://twitter.com/share?text=The final guide to web scraping with Node.js - &url=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Twitter" onclick="ga('send', 'event', 'share', 'clickShareOnTwitter');"><span id="twitter-share" class="text-[#1DA1F2]"><img src="/images/social-icons/twitter.svg" alt="Twitter" class="sharing-common"> </span></a><a href="http://www.facebook.com/sharer.php?u=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Facebook" onclick="ga('send', 'event', 'share', 'clickShareOnFacebook');"><span id="facebook-share" class="text-[#1877F2]"><img src="/images/social-icons/facebook.svg" alt="Facebook" class="sharing-common"> </span></a><a href="https://t.me/share/url?url=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Telegram" onclick="ga('send', 'event', 'share', 'clickShareOnTelegram');"><span id="telegram-share" class="text-[#0088cc]"><img src="/images/social-icons/telegram.svg" alt="Telegram" class="sharing-common"> </span></a><a href="https://api.whatsapp.com/send?text=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Whatsapp" onclick="ga('send', 'event', 'share', 'clickShareOnWhatsapp');"><span id="whatsapp-share" class="text-[#25d366]"><img src="/images/social-icons/whatsapp.svg" alt="WhatsApp" class="sharing-common"></span></a></span></div></div></header><div class="entry-content clearfix font-body text-xl text-gray"><p>Web scraping is the process of extracting data from a website in an automated way and Node.js can be used for web scraping. Even though other languages and frameworks are more popular for web scraping, Node.js can be utilized well to do the job too. In this post, we will learn how to do web scraping with Node.js for websites that don’t need and need Javascript to load. Let’s get started!</p><img class="center" loading="lazy" src="/images/nodejs-web-scraping/01nodejs-web-scraping.jpg" title="Web scraping with Nodejs for webpages that need or do not need JavaScript to render" alt="Web scraping with Nodejs for webpages that need or do not need JavaScript to render"><h2 id="table-of-contents" tabindex="-1">Table of contents <a class="direct-link" href="#table-of-contents">#</a></h2><ul><li><a href="#table-of-contents">Table of contents</a></li><li><a href="#web-scraping-the-dos-and-donts">Web scraping the dos and don’ts</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#web-scraping-with-nodejs-the-simple-example">Web scraping with Node.js the simple example</a><ul><li><a href="#axios-and-cheerio-for-nodejs-web-scraping">Axios and Cheerio for Node.js web scraping</a></li></ul></li><li><a href="#nodejs-web-scraping-rendering-javascript">Node.js web scraping rendering JavaScript</a><ul><li><a href="#puppeteer-for-web-scraping">Puppeteer for web scraping</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="web-scraping-the-dos-and-don%E2%80%99ts" tabindex="-1">Web scraping the dos and don’ts <a class="direct-link" href="#web-scraping-the-dos-and-don%E2%80%99ts">#</a></h2><p>Web scraping can be very advantageous to aggregate data from multiple sources or even track what one’s competitor is doing. But, it can have its own <a href="https://techcrunch.com/2021/06/14/supreme-court-revives-linkedin-bid-to-protect-user-data-from-web-scrapers/">legal</a> and technical issues too. A general technical problem being too many requests coming from the same IP in a very short amount of time as the traffic is coming from a machine than a browser or a human.</p><p>Even when scraping a website it is best to <a href="https://www.promptcloud.com/blog/how-to-read-and-respect-robots-file/">respect the robots.txt file</a> and be nice to the maintainers of the website. Don’t be that person who would send 50 requests per second to a website from the same IP address adding unnecessary load to the servers and making the website slow for other users. Next up, we will look at an example of a simple web scraper with Node.js.</p><p>Python’s <a href="https://scrapy.org/">Scrapy</a> framework might be one of the best tools to do web scraping but if you just know Javascript you can build a pretty decent web scraper with Node.js too.</p><h2 id="prerequisites" tabindex="-1">Prerequisites <a class="direct-link" href="#prerequisites">#</a></h2><p>Before we dive into the code, below are some prerequisites</p><ol><li>You have Node.js (preferably the latest LTS version) and NPM node running on your machine</li><li>Instaling NPM modules is known to you</li><li>Any prior knowledge or experience of <a href="https://en.vpnwelt.com/web-scraping-tools/">web scraping</a>, CSS selectors, or Xpath will be helpful.</li></ol><p>Let’s get started with some code now.</p><h2 id="web-scraping-with-node.js-the-simple-example" tabindex="-1">Web scraping with Node.js the simple example <a class="direct-link" href="#web-scraping-with-node.js-the-simple-example">#</a></h2><p>Websites and webpages can basically be divided into two broad categories. The first segment doesn’t need JavaScript rendering to show most of the content of the webpage, and the second needs Javascript execution to render any of its content. The first group of websites is much easier to scrape because the HTML rendered is almost the same for a browser that can execute Javascript compared to a bot that cannot execute JavaScript.</p><p>The second set of websites are mainly the Single Page Applications (SPA) that are built with JavaScript framework/libraries like React which need JavaScript execution to show any relevant content. We will see an example later for this class of websites. For now, we will dive into an example that doesn’t need any Javascript execution to get the meaningful contents of the website. For this simple example, we will use Axios and Cheerio to scrape a property listing website called <a href="http://Domain.com">Domain.com</a>,au to check how many rental properties are listed for a given postal code.</p><p>You can use <a href="https://brightdata.grsm.io/gva84uxcbadg">Bright data</a> to scarpe data from multiple sources. It also has proxy to make web scraping even more easier.</p><h3 id="axios-and-cheerio-for-node.js-web-scraping" tabindex="-1">Axios and Cheerio for Node.js web scraping <a class="direct-link" href="#axios-and-cheerio-for-node.js-web-scraping">#</a></h3><p>Prior to writing some code to scrape out information. It is best we analyze some patterns that will make our work easier. There are two main things to consider while scraping content, they are the URL and the structure of the page(s) you want to scrape the information out of. URLs have patten, in our example, if you search for rental properties on Domain the URL with postcode looks like: <code>https://www.domain.com.au/rent/?postcode=2000&amp;excludedeposittaken=1</code> so 2000 is the postcode part that can be changed to any valid postal code in Australia and it will work.</p><p>Similarly, when we inspect the page and look for the part we need that is the no. of properties in that postcode. It is available in a “strong” tag inside the “h1” tag. It is easy to see in the inspector of your browser of choice, I am using chrome below:</p><img class="center" loading="lazy" src="/images/nodejs-web-scraping/02nodejs-web-scraping-browser.jpg" title="Using chrome inspect for Node.js web scraping" alt="Using chrome inspect for Node.js web scraping"><p>Here <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors">CSS selectors</a> are your best friend, <a href="https://devhints.io/xpath">XPATH</a> is another powerful option but generally, I prefer CSS selectors. Below is a quick look at the innerText property of ‘h1&gt;strong’ which gives out the text we are after:</p><img class="center" loading="lazy" src="/images/nodejs-web-scraping/03nodejs-web-scraping-dollor.jpg" title="CSS selector and inner text for Node.js web scraping" alt="CSS selector and inner text for Node.js web scraping"><p>Now as we know what to target for in the webpage, below is a quick example of getting the number of properties open for rent in a given postcode of Australia pulled in from <a href="http://Domain.com.au">Domain.com.au</a> rental listing page using Axios and Cheerio:</p><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> axios <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'axios'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> cheerio <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'cheerio'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token punctuation">(</span><span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span><br>  <span class="token keyword">const</span> args <span class="token operator">=</span> process<span class="token punctuation">.</span>argv<span class="token punctuation">.</span><span class="token function">slice</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token keyword">const</span> postCode <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">||</span> <span class="token number">2000</span><span class="token punctuation">;</span><br>  <span class="token keyword">const</span> url <span class="token operator">=</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">https://www.domain.com.au/rent/?postcode=</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>postCode<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">&amp;excludedeposittaken=1</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">;</span><br>  <span class="token keyword">try</span> <span class="token punctuation">{</span><br>    <span class="token keyword">const</span> response <span class="token operator">=</span> <span class="token keyword">await</span> axios<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">const</span> $ <span class="token operator">=</span> cheerio<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">const</span> noOfProperties <span class="token operator">=</span> <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'h1>strong'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>noOfProperties<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string"> are open for rent in </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>postCode<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string"> postcode of Australia on Domain</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span>e<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    console<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">Error while fetching rental properties for </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>postCode<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string"> - </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>e<span class="token punctuation">.</span>message<span class="token interpolation-punctuation punctuation">}</span></span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>You can install axios and cheerio with <code>npm i --save axios cheerio</code> to any Node.js project initiated with an <code>npm install -y</code>.</p><p>In the above code, first, we require both <a href="https://github.com/axios/axios">Axios</a> and <a href="https://github.com/cheeriojs/cheerio">Cheerio</a> and then we create an async <a href="https://developer.mozilla.org/en-US/docs/Glossary/IIFE">IIFE</a> (Immediately Invoked Function Expression) as we would like to use await inside it. Given it is immediately invoked we don’t need to explicitly call the function.</p><p>Inside the function, we get the arguments from the command line if any. Then we set the <code>postCode</code> as the third argument from the command like <code>node axios-cheerio.js 2100</code>, in the above code, the <code>postCode</code> will be set to 2100.</p><p>Subsequently, we set the URL to be the domain’s URL for finding rental properties in a given postcode. After that we call the URL to get its HTML using Axios, we do an await to unwrap the promise. Once we have the response, we pass it to cheerio with cheerio load to parse the response body. Consequently, as we have the full HTML we use Cheerio’s easy Jquery like API to parse out the text for the strong HTML tag inside the H1 tag which has a value like <code>217 properties</code>.</p><p>Then finally we print the message and add more strings to show output on the console. If we wanted to scrape multple URLs at once that can be achieve with <a href="/blog/2022/07/javascript-promise-all/">JavaScript Promise.all</a>. If you are sending requests to multiple URLs it would be better to <a href="/blog/2022/08/javascript-wait-1-second/">wait 1 second</a> before sending a request to another URL. This will make sure that your IP is not blocked by the website.</p><p>In case of any error, we just log the error message. The script when run with <code>node axios-cheerio.js 2100</code> gives the following output:</p><img class="center" loading="lazy" src="/images/nodejs-web-scraping/04axios-cheerio-domain.jpg" title="Node.js web scraping with Axios and Cheerio for Domain" alt="Node.js web scraping with Axios and Cheerio for Domain"><p>Great our basic scraper with Axios and Cheerio is working. The above code is available in the <a href="https://github.com/geshan/nodejs-web-scraping/pull/2">pull request</a>. If you want a shortcut method I have created <a href="https://www.npmjs.com/package/@geshan/axrio">Axrio</a> too which is used in the <a href="https://github.com/geshan/domain-scraper">Domain scraper</a> project I wrote up in 2018.</p><p>Axios and Cheerio are just one of the combinations you can use. In place of Axios, you can use other libraries like Got, Superagent, and <a href="https://blog.logrocket.com/5-ways-to-make-http-requests-in-node-js/">the likes</a>. In place of Cheerio, you can also try out <a href="https://www.npmjs.com/package/jsdom">JsDOM</a>. The main point is to get the HTML and parse it to extract out the information we need from the HTML.</p><p>Next up, we will look at how to scrape web pages that require JavaScript to render any meaningful content for our Node.js web scraping tutorial.</p><h2 id="node.js-web-scraping-rendering-javascript" tabindex="-1">Node.js web scraping rendering JavaScript <a class="direct-link" href="#node.js-web-scraping-rendering-javascript">#</a></h2><p>Domain was a relatively easy website as it renders the full HTML with server-side rendering. Now if we use Axios and Cheerio to scrape the job titles from Workable’s <a href="https://jobs.workable.com/">job listing</a> page it will find nothing. Because the page renders no jobs until the JavaScript on the page fires up calls the respective API and paints the response from the API.</p><p>These types of Single Page Applications (SPA) will need a real or <a href="https://en.wikipedia.org/wiki/Headless_browser">headless browser</a> to execute the JavaScript on the page and get the HTML to the scraper as if it would work for a browser. Let’s use Puppeteer to scrape the job titles from Workable’s jobs page.</p><p><a href="https://github.com/puppeteer/puppeteer">Puppeteer</a> is a Node library that provides a high-level API to control Chrome or Chromium. It runs headless (no GUI) by default but can run on full GUI mode too. It can be used for a lot of other things than just rendering JavaScript to assist in scraping. It can be used to generate screenshots or PDFs, fill up forms, use for automated testing, etc. Speaking of testing, there are only two <a href="/blog/2016/03/there-are-only-two-types-of-automated-software-tests/">types of automated tests</a> fast ones and not fast ones.</p><h3 id="puppeteer-for-web-scraping" tabindex="-1">Puppeteer for web scraping <a class="direct-link" href="#puppeteer-for-web-scraping">#</a></h3><p>To use Puppeteer, we can install it with <code>npm i --save puppeteer</code>, it will download the recent version of chromium too. If you want to use your own browser you can try <code>puppeteer-core</code>. For this guide, we will use puppeteer to keep things simple.</p><p>To scrape the job titles on the first page of Workable we will use the following code:</p><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> puppeteer <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'puppeteer'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token punctuation">(</span><span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span><br>  <span class="token keyword">try</span> <span class="token punctuation">{</span><br>    <span class="token keyword">const</span> browser <span class="token operator">=</span> <span class="token keyword">await</span> puppeteer<span class="token punctuation">.</span><span class="token function">launch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">const</span> page <span class="token operator">=</span> <span class="token keyword">await</span> browser<span class="token punctuation">.</span><span class="token function">newPage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">const</span> navigationPromise <span class="token operator">=</span> page<span class="token punctuation">.</span><span class="token function">waitForNavigation</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br>    <span class="token keyword">await</span> page<span class="token punctuation">.</span><span class="token function">goto</span><span class="token punctuation">(</span><span class="token string">'https://jobs.workable.com/'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">await</span> page<span class="token punctuation">.</span><span class="token function">setViewport</span><span class="token punctuation">(</span><span class="token punctuation">{</span> <span class="token literal-property property">width</span><span class="token operator">:</span> <span class="token number">1440</span><span class="token punctuation">,</span> <span class="token literal-property property">height</span><span class="token operator">:</span> <span class="token number">744</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">await</span> navigationPromise<span class="token punctuation">;</span><br><br>    <span class="token keyword">await</span> page<span class="token punctuation">.</span><span class="token function">waitForSelector</span><span class="token punctuation">(</span><span class="token string">'ul li h3 a'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">let</span> jobTitles <span class="token operator">=</span> <span class="token keyword">await</span> page<span class="token punctuation">.</span><span class="token function">$$eval</span><span class="token punctuation">(</span><span class="token string">'ul li h3 a'</span><span class="token punctuation">,</span> <span class="token parameter">titles</span> <span class="token operator">=></span> <span class="token punctuation">{</span><br>      <span class="token keyword">return</span> titles<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token parameter">title</span> <span class="token operator">=></span> title<span class="token punctuation">.</span>innerText<span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">Job Titles on first page of Workable are: </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>jobTitles<span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token string">', '</span><span class="token punctuation">)</span><span class="token interpolation-punctuation punctuation">}</span></span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">await</span> browser<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span>e<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">Error while fetching workable job titles </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>e<span class="token punctuation">.</span>message<span class="token interpolation-punctuation punctuation">}</span></span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>The code has been partially generated with the <a href="https://chrome.google.com/webstore/detail/headless-recorder/djeegiggegleadkkbgopoonhjimgehda?hl=en">Headless Recorder</a> Google Chrome Plugin, you can view its code on <a href="https://github.com/checkly/headless-recorder">GitHub</a> too if you are interested.</p><p>The code at first includes puppeteer. Then in the IIFE async function similar to the above example, starts the browser and open a new tab. After that, it goes to <code>https://jobs.workable.com</code> and sets the viewport. Consequently, it waits for the navigation to and waits for the selector <code>ul li h3 a</code>. Then it gets all the <code>a</code> tags in <code>ul li h3</code>, all 10 of them, and loops through them to get the inner text that holds the job titles. Which is set in the <code>jobTitles</code> array. After that, it logs all the scraped job titles and then closes the browser. We can also use other <a href="/blog/2021/01/nodejs-logging-library/">Node.js logging libraries</a> in place of console.log.</p><p>This is how it looks when you run it:</p><img class="center" loading="lazy" src="/images/nodejs-web-scraping/05puppeteer-workable.jpg" title="Node.js web scraping with Puppeteer on Workable" alt="Node.js web scraping with Puppeteer on Workable"><p>If the code is run with docker it will need a <a href="https://github.com/puppeteer/puppeteer/blob/main/docs/troubleshooting.md#tips">different way</a> to start the browser. For the above example, I am running it on a Mac. The above code is available as a <a href="https://github.com/geshan/nodejs-web-scraping/pull/4">pull request</a> for your reference. We could have possibly taken the whole HTML rendered after executing the JavaScript and put it into Cheerio to parse it but the above method works too.</p><p>All the working code is available as a <a href="https://github.com/geshan/nodejs-web-scraping">Github repository</a> for your reference. We can also use <a href="/blog/2020/11/nodejs-with-docker/">Node.js with Docker</a> to make the code run seamlessly in multiple operating systems and environments.</p><p>In addition to scraping just one page, we could get all the links and loop through (or even better promise.all) the pages but at that point, it would be a full-on spider than just web page scraping.</p><p>Another alternative to Puppeteer is <a href="https://playwright.dev/">Playwright</a>. It is similar to puppeteer and has a similar API, the advantage is it supports multiple <a href="https://playwright.dev/docs/browsers">browsers</a> like Firefox and Safari. The headless recorder plugin can generate a good starting script for both Puppeteer and Playwright so you can get a very good starting point if you are not well versed in writing such automation scripts. If you want to learn web <a href="https://www.scrapingdog.com/blog/web-scraping-with-python/">scraping with Python</a>, here is the perfect guide for you.</p><h2 id="conclusion" tabindex="-1">Conclusion <a class="direct-link" href="#conclusion">#</a></h2><p>We saw how to scrape web pages with Node.js for both types of web pages that don’t require JavaScipt to render meaningful HTML and that requires JavaScript. Using your browser’s inspect tool and some URL pattern matching will surely help you scraper web pages much better.</p></div><div class="flex items-center justify-between gap-3 md:gap-4 flex-wrap md:flex-nowrap py-2 border-y border-lightbg mt-4"><div class="flex items-center justify-start md:gap-4 gap-2 flex-wrap w-2/3"><div class="flex justify-start items-center gap-3 md:gap-4"><img src="/images/favicons/favicon-32x32-pp.png" alt="Geshan Manandhar" class="w-10 h-10 rounded-full object-cover flex-shrink-0"> <span class="text-gray font-medium font-ui text-md md:text-xl uppercase tracking-wide text-start">Geshan Manandhar</span></div><time datetime="2021-09-18" data-updated="true"><time class="entry-date" datetime="2021-09-18"><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">18-Sep-2021 </span></time></time><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">12 MIN READ</span></div><button type="button" id="share-button-bottom" class="flex items-center justify-center w-8 h-8 md:w-9 md:h-9 rounded text-lightGray hover:border-gray-400 hover:bg-gray-50 transition-colors flex-shrink-0" aria-label="Share this post" onclick="toggleShareIconsBottom(); ga('send', 'event', 'share', 'clickShareOnPost');"><img src="/images/shareIcon.svg" alt="Share this post" class="w-6 h-6"></button></div><div id="share-icons-container-bottom" class="share-icons-bottom print:hidden hidden mx-auto" aria-label="Share this post"><div class="w-full flex items-center justify-center mx-auto gap-3"><span class="share-icons"><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on LinkedIn" onclick="ga('send', 'event', 'share', 'clickShareOnLinkedIn');"><span id="linkedin-share" class="text-[#0077B5]"><img src="/images/social-icons/linkedin.svg" alt="LinkedIn" class="sharing-common"> </span></a><a href="http://twitter.com/share?text=The final guide to web scraping with Node.js - &url=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Twitter" onclick="ga('send', 'event', 'share', 'clickShareOnTwitter');"><span id="twitter-share" class="text-[#1DA1F2]"><img src="/images/social-icons/twitter.svg" alt="Twitter" class="sharing-common"> </span></a><a href="http://www.facebook.com/sharer.php?u=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Facebook" onclick="ga('send', 'event', 'share', 'clickShareOnFacebook');"><span id="facebook-share" class="text-[#1877F2]"><img src="/images/social-icons/facebook.svg" alt="Facebook" class="sharing-common"> </span></a><a href="https://t.me/share/url?url=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Telegram" onclick="ga('send', 'event', 'share', 'clickShareOnTelegram');"><span id="telegram-share" class="text-[#0088cc]"><img src="/images/social-icons/telegram.svg" alt="Telegram" class="sharing-common"> </span></a><a href="https://api.whatsapp.com/send?text=https://geshan.com.np/blog/2021/09/web-scraping-nodejs/" target="_blank" title="Share 'The final guide to web scraping with Node.js' on Whatsapp" onclick="ga('send', 'event', 'share', 'clickShareOnWhatsapp');"><span id="whatsapp-share" class="text-[#25d366]"><img src="/images/social-icons/whatsapp.svg" alt="WhatsApp" class="sharing-common"></span></a></span></div></div></article><div class="mt-3"><a href="/blog/categories/software-engineering/" title="Software Engineering" class="background-lightbg mr-4 mb-2 inline-block mt-2 rounded border-2 bg-gray-100 font-semibold font-ui text-gray hover:text-gray-400 px-3 py-1 text-xl border-gray-300 cursor-pointer hover:border-gray-400">software engineering </a><a href="/blog/categories/javascript/" title="Javascript" class="background-lightbg mr-4 mb-2 inline-block mt-2 rounded border-2 bg-gray-100 font-semibold font-ui text-gray hover:text-gray-400 px-3 py-1 text-xl border-gray-300 cursor-pointer hover:border-gray-400">javascript </a><a href="/blog/categories/node.js/" title="Node.js" class="background-lightbg mr-4 mb-2 inline-block mt-2 rounded border-2 bg-gray-100 font-semibold font-ui text-gray hover:text-gray-400 px-3 py-1 text-xl border-gray-300 cursor-pointer hover:border-gray-400">node.js</a></div><section class="md:w-full mx-auto mt-4"><h3 class="comments font-heading">Comments</h3><div id="disqus_thread"></div><button id="disqus_trigger" class="font-ui text-blackText hover:border-darkAvocado border-blacktext hover:shadow-lg border-2 transition ease-in-out delay-100 px-3 py-2 pt-2 mt-2 rounded-md text-center block h-auto text-xl" onclick="load_disqus()">Post a Comment</button><div id="disqus_thread" aria-live="polite"></div></section></div></div><section class="md:w-full mx-auto mt-4 bg-lightAvocado p-4 rounded-lg pb-8"><div class="max-w-6xl mx-auto md:py-12 px-4"><h2 class="text-4xl text-darkAvocado font-heading font-regular flex-shrink-0 py-8 tracking-normal leading-[105%] md:leading-[105%]"><span class="text-lightGray italic">Related</span> <span class="text-blackText">Blogs</span></h2><div class="grid grid-cols-1 md:grid-cols-2 gap-8"><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2023/12/nodejs-duet-ai-vs-code/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to write and deploy a basic Node.js API with Duet AI on VS Code a step-by-step guide</a> <time class="font-medium text-xl text-textColor uppercase font-ui">18-Dec-2023 &nbsp;&nbsp;&nbsp; 9 min read</time><p class="text-xl text-gray font-ui">Learn how to write and deploy a basic Node.js API with Duet AI on VS Code, in this step-by-step tutorial with 20+ screenshots!</p></div><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2022/08/nodejs-alternatives/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">Node.js alternatives: Exploring Deno and Bun (with code examples)</a> <time class="font-medium text-xl text-textColor uppercase font-ui">18-Aug-2022 &nbsp;&nbsp;&nbsp; 12 min read</time><p class="text-xl text-gray font-ui">Learn about 2 Node.js alternatives in JavaScript sphere, Deno and Bun with a simple code example.</p></div><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2022/07/javascript-promise-all/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to use JavaScript Promise.all with real-life code example</a> <time class="font-medium text-xl text-textColor uppercase font-ui">01-Jul-2022 &nbsp;&nbsp;&nbsp; 14 min read</time><p class="text-xl text-gray font-ui">Learn how to use JavaScript Promise.all with a real-life Axios API get call code example compared to a sequential call.</p></div><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2022/06/typescript-optional-parameters/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to use TypeScript optional parameters with example code</a> <time class="font-medium text-xl text-textColor uppercase font-ui">12-Jun-2022 &nbsp;&nbsp;&nbsp; 6 min read</time><p class="text-xl text-gray font-ui">Learn how to use optional paramters in typescript function with a simple yet useful example in this post.</p></div></div></div></section><section class="bg-avocado md:py-0 py-12 px-4"><div class="max-w-6xl mx-auto"><div class="md:hidden"><h2 class="mb-4 text-3xl font-heading font-regular text-textColor break-words tracking-[-0.01em] leading-[105%] md:leading-[105%]"><span class="text-textColor italic">Stay</span><span class="text-blackText"> Connected</span></h2><p class="text-base text-blackText font-body font-regular mb-6">Follow me on LinkedIn for new posts, engineering insights, and tech takes — straight from the trenches.</p><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="inline-block bg-darkAvocado text-base text-white px-6 py-3 rounded-lg font-body font-regular hover:opacity-90 transition-opacity w-full text-center">Follow on LinkedIn &nbsp;→</a></div><div class="hidden md:grid lg:hidden grid-cols-3 gap-8 items-center"><div class="z-10 col-span-2"><h2 class="mb-4 text-2xl md:text-4xl font-heading font-regular text-textColor break-words tracking-[-0.01em] leading-[105%] md:leading-[105%]"><span class="text-textColor italic">Stay</span><span class="text-blackText"> Connected</span></h2><p class="text-xl text-blackText font-body font-regular mb-6">Follow me on LinkedIn for new posts, engineering insights, and tech takes — straight from the trenches.</p><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="inline-block bg-darkAvocado text-xl text-white px-6 py-3 rounded-lg font-body font-regular hover:opacity-90 transition-opacity">Follow on LinkedIn &nbsp;→</a></div><div class="flex items-center justify-end col-span-1"><img class="w-32 h-auto" src="/images/theme/new_logo.svg" alt="Geshan"></div></div><div class="hidden lg:grid grid-cols-2 gap-8 lg:gap-12 items-center justify-between h-full"><div class="z-10"><h2 class="mb-4 text-2xl md:text-4xl font-heading font-regular text-textColor break-words tracking-[-0.01em] leading-[105%] md:leading-[105%]"><span class="text-textColor italic">Stay</span><span class="text-blackText"> Connected</span></h2><p class="text-xl text-blackText font-body font-regular mb-6">Follow me on LinkedIn for new posts, engineering insights, and tech takes — straight from the trenches.</p><p class="text-xl text-blackText font-body font-regular mb-6">A big thank you for supporting this ad. free, unobstructive (no overlays, no pop-ups) blog.</p></div><div class="flex items-center gap-12 w-full md:w-auto justify-end self-end"><img class="w-16 md:w-32 h-auto" src="/images/theme/new_logo.svg" alt="Geshan"> <a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="inline-block bg-darkAvocado text-xl text-white px-6 py-3 rounded-lg font-body font-regular hover:opacity-90 transition-opacity w-full md:w-auto text-center md:text-left">Follow on LinkedIn &nbsp;→</a></div></div></div></section></div></div></div></main><footer role="contentinfo"><footer class="bg-avocado sm:px-4"><div class="max-w-6xl mx-auto flex flex-col md:flex-row sm:flex-col justify-between gap-2 items-center sm:items-center md:items-center py-10 font-nav text-lightGray text-base font-regular"><div class="pb-0 sm:pb-2 text-gray"><span class="pr-4">Copyright © 2026 Geshan Manandhar.</span></div><div class="pb-0 sm:pb-2"><ul class="flex"><li class="hover:text-gray-300 text-lg pr-4 cursor-pointer text-gray"><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer nofollow" class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 1000 1000"><path fill="currentColor" d="M1000 267q0 112-78 188L747 631q-78 78-189 78q-97 0-171-63l115-115q26 17 56 17q44 0 75-31l175-176q31-29 31-74q0-44-30.5-74.5T734 162q-25 0-49.5 12T652 208H414L546 79Q626 1 734 1q110 0 188 78t78 188zm-387 89L498 471q-26-17-56-17q-44 0-75 31L192 661q-31 29-31 74q0 44 30.5 74.5T266 840q25 0 49.5-12t32.5-34h238L454 923q-80 78-188 78q-110 0-188-78T0 735q0-112 78-188l175-176q78-78 189-78q97 0 171 63z"/></svg> LinkedIn</a></li><li class="hover:text-gray-300 text-lg pr-4 cursor-pointer text-gray"><a href="https://www.twitter.com/geshan" target="_blank" rel="noopener noreferrer nofollow" class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 1000 1000"><path fill="currentColor" d="M1000 267q0 112-78 188L747 631q-78 78-189 78q-97 0-171-63l115-115q26 17 56 17q44 0 75-31l175-176q31-29 31-74q0-44-30.5-74.5T734 162q-25 0-49.5 12T652 208H414L546 79Q626 1 734 1q110 0 188 78t78 188zm-387 89L498 471q-26-17-56-17q-44 0-75 31L192 661q-31 29-31 74q0 44 30.5 74.5T266 840q25 0 49.5-12t32.5-34h238L454 923q-80 78-188 78q-110 0-188-78T0 735q0-112 78-188l175-176q78-78 189-78q97 0 171 63z"/></svg> Twitter</a></li><li class="hover:text-gray-300 text-lg pr-4 cursor-pointer text-gray"><a href="https://github.com/geshan" target="_blank" rel="noopener noreferrer nofollow" class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 1000 1000"><path fill="currentColor" d="M1000 267q0 112-78 188L747 631q-78 78-189 78q-97 0-171-63l115-115q26 17 56 17q44 0 75-31l175-176q31-29 31-74q0-44-30.5-74.5T734 162q-25 0-49.5 12T652 208H414L546 79Q626 1 734 1q110 0 188 78t78 188zm-387 89L498 471q-26-17-56-17q-44 0-75 31L192 661q-31 29-31 74q0 44 30.5 74.5T266 840q25 0 49.5-12t32.5-34h238L454 923q-80 78-188 78q-110 0-188-78T0 735q0-112 78-188l175-176q78-78 189-78q97 0 171 63z"/></svg> Github</a></li></ul></div></div></footer></footer><script src="/js/all.min.js" defer="defer"></script></body></html>