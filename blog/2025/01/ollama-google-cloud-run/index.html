<!doctype html><html class="no-js" lang="en"><head><meta charset="utf-8"><meta name="author" content="Geshan Manandhar"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="Learn how to run and host Gemma 2:2b with Ollama on Google Cloud Run in this step-by-step tutorial. You can use Gemma with an API, too, using Ollama"><meta name="keywords" content="ollama google cloud run, ollama gemma, gemma ollama, ollama cloud, ollama gcp, ollama cloud run"><meta name="p:domain_verify" content="e654c68562abebfa25c291f59d7d00e8"><meta property="og:type" content="website"><meta property="og:url" content="https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/"><meta property="og:title" content="How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]"><meta property="og:description" content="Learn how to run and host Gemma 2:2b with Ollama on Google Cloud Run in this step-by-step tutorial. You can use Gemma with an API, too, using Ollama"><meta property="og:site_name" content="Geshan&#39;s Blog"><meta property="og:image" content="https://geshan.com.np/images/ollama-google-cloud-run/01ollama-google-cloud-run.jpg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:widgets:new-embed-design" content="on"><meta name="twitter:site" content="@geshan"><meta name="twitter:creator" content="@geshan"><meta name="twitter:title" content="How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]"><meta name="twitter:description" content="Learn how to run and host Gemma 2:2b with Ollama on Google Cloud Run in this step-by-step tutorial. You can use Gemma with an API, too, using Ollama"><meta name="twitter:image:src" content="https://geshan.com.np/images/ollama-google-cloud-run/01ollama-google-cloud-run.jpg"><link rel="canonical" href="https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/"><meta property="fb:pages" content="30717799226"><meta property="fb:app_id" content="106030259434380"><meta name="monetization" content="$ilp.uphold.com/aKHWpqhphm9f"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicons/favicon-16x16.png"><link href="/atom.xml" rel="alternate" title="Geshan&#39;s Blog" type="application/atom+xml"><title>How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]</title><link rel="preconnect" href="/" crossorigin><link rel="preload" href="/css/fonts.css" as="style"><link rel="preload" href="/fonts/source-sans-4/source-serif-4-latin-400-normal.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="/fonts/source-sans-4/source-serif-4-latin-500-normal.woff2" as="font" type="font/woff2" crossorigin><link rel="preload" href="/fonts/source-sans-pro/source-sans-pro-latin-400-normal.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="/css/fonts.css"><link rel="stylesheet" href="/css/tw-006.css"><link rel="alternate" href="/atom.xml" type="application/atom+xml" title="Geshan&#39;s Blog"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-P3NXCVQEPE"></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-P3NXCVQEPE');</script><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWT2D9T');</script><script src="https://cdn.jsdelivr.net/npm/@statsig/js-client@3/build/statsig-js-client+session-replay+web-analytics.min.js?apikey=client-rYO7rX8WSUyyLg9pKJwymLxM71tCE0CKgxgtUj4akzK"></script><link rel="manifest" href="/manifest.json"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="application-name" content="Geshan.com.np"><meta name="apple-mobile-web-app-title" content="Geshan.com.np"><meta name="msapplication-starturl" content="/index.html"><meta name="theme-color" content="#6947E7"><script>if ("serviceWorker" in navigator) {
    navigator.serviceWorker.register("/sw.js").then(function(registration) {
        console.log('ServiceWorker registration successful with scope: ', registration.scope);
    }, function(err) {
        console.log('ServiceWorker registration failed: ', err);
    });
  }</script></head><body class="overflow-x-hidden font-ui flex flex-col min-h-screen"><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWT2D9T" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><header role="banner"><div><nav class="bg-white" role="navigation"><div class="w-full md:max-w-6xl mx-auto py-4 px-4"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><a href="/" class="flex items-center"><img class="h-12 w-12" src="/images/theme/new_logo.svg" alt="Geshan G"></a></div><div class="flex items-center gap-12"><div class="hidden sm:flex items-center gap-12"><a href="/posts/1/" class="uppercase text-base font-ui font-medium text-gray hover:text-midgrey transition-colors" aria-current="page">Posts </a><a href="/about/" class="uppercase text-base font-ui font-medium text-gray hover:text-midgrey transition-colors" aria-current="page">About Me </a><a href="https://newsletter.geshan.com.np/" class="uppercase text-base font-ui font-medium text-gray hover:text-midgrey transition-colors" aria-current="page">Newsletter</a></div><form class="search flex items-center" action="https://www.google.com/search" method="GET"><input type="hidden" name="sitesearch" value="geshan.com.np"><div class="relative"><input class="bg-gray-100 border border-neutralGray rounded-lg py-2 pl-10 pr-4 font-body text-sm focus:outline-none focus:ring-2 focus:ring-avocado focus:border-transparent w-40" type="text" name="q" placeholder="Search" label="search"> <svg class="absolute left-3 top-1/2 transform -translate-y-1/2 w-4 h-4 text-neutralGray" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"/></svg></div></form><button type="button" class="sm:hidden inline-flex items-center justify-center p-2 rounded-md text-black focus:outline-none focus:ring-2 focus:ring-inset focus:ring-avocado" onclick="mobileView()" aria-controls="mobile-menu" aria-expanded="false"><span class="sr-only">Open main menu</span> <svg class="w-6 h-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewbox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg></button></div></div></div><div class="mobile-menu fixed inset-0 z-40 hidden sm:hidden bg-black bg-opacity-40" role="dialog" aria-modal="true"><div class="absolute inset-0" onclick="mobileView()" aria-hidden="true"></div><div class="mobile-menu-panel relative ml-auto flex h-full w-10/12 max-w-sm flex-col justify-start bg-white shadow-xl"><div class="flex items-center justify-between px-4 py-4 border-b border-gray-200"><div class="flex items-center gap-3"><img class="h-8 w-8" src="/images/theme/new_logo.svg" alt="Geshan G"> <span class="text-lg font-semibold text-textColor font-body">Geshan's Blog</span></div><button type="button" class="inline-flex items-center justify-center rounded-full p-2 text-gray-700 hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-avocado" onclick="mobileView()" aria-label="Close main menu"><svg class="h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/></svg></button></div><nav class="overflow-y-auto px-4 py-6 space-y-2"><a href="/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">Home </a><a href="/posts/1/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">Posts </a><a href="/about/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">About Me </a><a href="https://newsletter.geshan.com.np/" class="block rounded-lg px-3 py-2 text-base font-medium font-ui text-black hover:bg-lightAvocado" aria-current="page">Newsletter</a></nav><div class="px 4 py-4 border-t border-gray-200"><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="rounded-lg bg-darkAvocado px-4 py-2 text-base font-regular font-body text-white hover:bg-avocado hover:text-black transition-colors w-2/3 mx-auto ml-4">Connect on LinkedIn</a></div></div></div></nav></div></header><main id="wrap" role="main" class="flex-grow md:px-0"><div id="content"><div class="row"><div><script type="application/ld+json">{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Geshan&#39;s Blog",
    "alternativeHeadline": "How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]",
    "image": "https://geshan.com.np/images/ollama-google-cloud-run/01ollama-google-cloud-run.jpg",
    "editor": "Geshan Manandhar",
    "genre": "AI",
    "keywords": "ollama google cloud run, ollama gemma, gemma ollama, ollama cloud, ollama gcp, ollama cloud run",
    "url": "https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/",
    "datePublished": "2025-01-20",
    "dateCreated": "2025-01-20",
    "dateModified": "2025-01-20",
    "description": "Learn how to run and host Gemma 2:2b with Ollama on Google Cloud Run in this step-by-step tutorial. You can use Gemma with an API, too, using Ollama",
    "articleBody": "Ollama is a great way to run many open Large Language Models (LLMs). You can run Google Gemma 2, Phi 4, Mistral, and Llama 3 on your machine or the cloud with Ollama. You can also host these open LLMs as APIs using Ollama. In this post, you will learn how to host Gemma 2 (2b) with Ollama 0.5.x on Google Cloud Run; let’s get started!Table of contents #Why Google Cloud RunCreate a GCS bucketDeploy Ollama on Google Cloud RunWire up GSC bucket as a Cloud Run VolumeTesting Gemma 2 with Ollama on Google Cloud ConsoleConclusion[#conclusion]Why Google Cloud Run #Good question; I have written multiple blog posts about Google Cloud Run and also given a couple of talks in the past years, Some great reasons to use Google Cloud Run to host open LLMs with serverless containers are:The resources (like CPU, memory, and even GPU) are allocated in a serverless way. Meaning you only pay for the time you use it.You don’t need to send data out of your VPC, putting security firstMore cost control without counting tokens, as the LLMs are self-hosted; you can define how the resources are allocated rather than just counting the number of tokens sent and received.Now that that&#39;s out of the way let’s access the Google Cloud Console and deploy Gemma 2 (2b—2 billion parameters) on Google Cloud Run.Create a GCS bucket #First, you will need an existing Project on Google Cloud, or you can create a new project. For this tutorial, we will assume that you have a new(ish) project. Since the project has already been selected, you will create a new Google Cloud Storage (GCS) bucket. You are creating a GCS bucket to store the files needed for the open LLM, which is Gemma2 2b in the case of this guide.To create a new bucket, search for  some code It will give an output as follows:If you go in the bucket and look at its contents, you will find Gemma 2 there:Google Cloud Run makes it easy to run any LLM on Ollama. You can run Phi 4, Llama 3, or any other model; you must pull it and run your command or POST with curl. You can also use libraries like LiteLLM to use the model in your apps using Ollama’s APIs. Please explore Ollama more on your own. You can also use Open WebUI to have a GUI on top of Oallma running Gemma 2 LLM.Conclusion #It is easy to run any LLM with Ollama on Google Cloud Run. Be careful of the access as Ollama APIs allow pulling models and even deleting them. With Cloud Run, you will only pay for the resources when you use it, which makes it ideal for experiments. I hope you learned something new from this post and keep experimenting.",
    "author": { "@type": "Person", "name": "Geshan Manandhar" },
    "publisher": {
      "@type": "Organization",
      "name": "Geshan Manandhar",
      "logo": { "@type": "ImageObject", "url": "https://geshan.com.np/images/favicons/favicon-32x32.png" }
    },
    "mainEntityOfPage": { "@type": "WebPage", "@id": "https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" }
  }</script><div class="progress-bar"></div><div class="max-w-6xl py-3 mx-auto grid-cols-12 grid gap-15 px-4 md:px-0 mb-20"><div class="col-span-12"><article class="md:w-full mx-auto"><header class="page-header text-center"><h1 class="font-semibold font-heading text-gray text-center mb-6 tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]</h1><div class="flex items-center justify-between gap-3 md:gap-4 flex-wrap md:flex-nowrap py-2 border-y border-lightbg mt-4"><div class="flex items-center justify-start md:gap-4 gap-2 flex-wrap w-2/3"><div class="flex justify-start items-center gap-3 md:gap-4"><img src="/images/favicons/favicon-32x32-pp.png" alt="Geshan Manandhar" class="w-10 h-10 rounded-full object-cover flex-shrink-0"> <span class="text-gray font-medium font-ui text-md md:text-xl uppercase tracking-wide text-start">Geshan Manandhar</span></div><time datetime="2025-01-20" data-updated="true"><time class="entry-date" datetime="2025-01-20"><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">20-Jan-2025 </span></time></time><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">11 MIN READ</span></div><button type="button" id="share-button" class="flex items-center justify-center w-8 h-8 md:w-9 md:h-9 rounded text-lightGray hover:border-gray-400 hover:bg-gray-50 transition-colors flex-shrink-0" aria-label="Share this post" onclick="toggleShareIcons(); ga('send', 'event', 'share', 'clickShareOnPost');"><img src="/images/shareIcon.svg" alt="Share this post" class="w-6 h-6"></button></div><div id="share-icons-container" class="share-icons print:hidden hidden" aria-label="Share this post"><div class="flex items-center justify-center gap-3"><span class="share-icons"><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on LinkedIn" onclick="ga('send', 'event', 'share', 'clickShareOnLinkedIn');"><span id="linkedin-share" class="text-[#0077B5]"><img src="/images/social-icons/linkedin.svg" alt="LinkedIn" class="sharing-common"> </span></a><a href="http://twitter.com/share?text=How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step] - &url=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Twitter" onclick="ga('send', 'event', 'share', 'clickShareOnTwitter');"><span id="twitter-share" class="text-[#1DA1F2]"><img src="/images/social-icons/twitter.svg" alt="Twitter" class="sharing-common"> </span></a><a href="http://www.facebook.com/sharer.php?u=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Facebook" onclick="ga('send', 'event', 'share', 'clickShareOnFacebook');"><span id="facebook-share" class="text-[#1877F2]"><img src="/images/social-icons/facebook.svg" alt="Facebook" class="sharing-common"> </span></a><a href="https://t.me/share/url?url=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Telegram" onclick="ga('send', 'event', 'share', 'clickShareOnTelegram');"><span id="telegram-share" class="text-[#0088cc]"><img src="/images/social-icons/telegram.svg" alt="Telegram" class="sharing-common"> </span></a><a href="https://api.whatsapp.com/send?text=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Whatsapp" onclick="ga('send', 'event', 'share', 'clickShareOnWhatsapp');"><span id="whatsapp-share" class="text-[#25d366]"><img src="/images/social-icons/whatsapp.svg" alt="WhatsApp" class="sharing-common"></span></a></span></div></div></header><div class="entry-content clearfix font-body text-xl text-gray"><p>Ollama is a great way to run many open Large Language Models (LLMs). You can run Google Gemma 2, Phi 4, Mistral, and Llama 3 on your machine or the cloud with <a href="https://ollama.com/">Ollama</a>. You can also host these open LLMs as APIs using Ollama. In this post, you will learn how to host Gemma 2 (2b) with Ollama 0.5.x on Google Cloud Run; let’s get started!</p><img class="center" src="/images/ollama-google-cloud-run/01ollama-google-cloud-run.jpg" title="How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]" alt="How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]"><h2 id="table-of-contents" tabindex="-1">Table of contents <a class="direct-link" href="#table-of-contents">#</a></h2><ul><li><a href="#why-google-cloud-run">Why Google Cloud Run</a></li><li><a href="#create-a-gcs-bucket">Create a GCS bucket</a></li><li><a href="#deploy-ollama-on-google-cloud-run">Deploy Ollama on Google Cloud Run</a><ul><li><a href="#wire-up-gsc-bucket-as-a-cloud-run-volume">Wire up GSC bucket as a Cloud Run Volume</a></li></ul></li><li><a href="#testing-gemma-2-with-ollama-on-google-cloud-console">Testing Gemma 2 with Ollama on Google Cloud Console</a></li><li>Conclusion[#conclusion]</li></ul><h2 id="why-google-cloud-run" tabindex="-1">Why Google Cloud Run <a class="direct-link" href="#why-google-cloud-run">#</a></h2><p>Good question; I have written multiple <a href="https://geshan.com.np/blog/categories/google-cloud-run/">blog posts</a> about Google Cloud Run and also given a couple of <a href="/blog/2019/11/from-0-to-working-serverless-url-for-a-containerized-app-with-google-cloud-run-slides-and-video/">talks</a> in the past years, Some great <a href="/blog/2019/11/why-use-google-cloud-run-5-compelling-reasons/">reasons</a> to use Google Cloud Run to host open LLMs with <a href="/blog/2023/04/serverless-containers/">serverless containers</a> are:</p><ul><li>The resources (like CPU, memory, and even GPU) are allocated in a serverless way. Meaning you only pay for the time you use it.</li><li>You don’t need to send data out of your <a href="https://cloud.google.com/vpc?hl=en">VPC</a>, putting security first</li><li>More cost control without counting tokens, as the LLMs are self-hosted; you can define how the resources are allocated rather than just counting the number of tokens sent and received.</li></ul><p>Now that that's out of the way let’s access the Google Cloud Console and deploy Gemma 2 (2b—2 billion parameters) on Google Cloud Run.</p><h2 id="create-a-gcs-bucket" tabindex="-1">Create a GCS bucket <a class="direct-link" href="#create-a-gcs-bucket">#</a></h2><p>First, you will need an existing Project on Google Cloud, or you can create a <a href="https://console.cloud.google.com/projectcrea">new project</a>. For this tutorial, we will assume that you have a new(ish) project. Since the project has already been selected, you will create a new Google Cloud Storage (GCS) bucket. You are creating a GCS bucket to store the files needed for the open LLM, which is Gemma2 2b in the case of this guide.</p><p>To create a new bucket, search for <code>bucket</code> on the search bar:</p><img class="center" src="/images/ollama-google-cloud-run/02search-buckets.jpg" loading="lazy" title="Search for a bucket on Google Cloud Console search bar" alt="Search for bucket on Google Cloud Console search bar"><p>Then select the <code>Buckets</code> option, as shown above. Then click the <code>+ Create</code> option on the “Buckets” page:</p><img class="center" src="/images/ollama-google-cloud-run/03create-bucket-button.jpg" loading="lazy" title="Click on the Create bucket button on the GCS buckets page" alt="Click on the Create bucket button on the GCS buckets page"><p>After that, name the bucket something unique, like <code>ollama-gemma2-2b-xyz.</code>. All buckets across GCP have unique names, so you might need a suffix. Then click the down arrow beside <code>Optimize storage for data-intensive workloads</code> and check the <code>Enable Hierarchical namespace on this bucket</code> checkbox as shown below:</p><img class="center" src="/images/ollama-google-cloud-run/04name-the-bucket.jpg" loading="lazy" title="Name the bucket and enable hierarchical namespace" alt="Name the bucket and enable hierarchical namespace"><p>This will help optimize the LLM access later. After that, select the bucket to be a single region and the <code>Region</code> as <code>us-central1 (Iowa)</code> as follows:</p><img class="center" src="/images/ollama-google-cloud-run/05select-bucket-region.jpg" loading="lazy" title="Make it single region bucket and select us-central1 region" alt="Make it single region bucket and select us-central1 region"><p>Then click <code>Continue</code>. Next, keep the <code>Storage Class</code> as <code>Standard</code> and then click <code>Continue</code>:</p><img class="center" src="/images/ollama-google-cloud-run/06select-standard-bucket.jpg" loading="lazy" title="Make it a standard bucket class" alt="Make it a standard bucket class"><p>After that, let the access control be on the bucket level (not <code>Fine-grained</code> ) and click <code>Continue</code>:</p><img class="center" src="/images/ollama-google-cloud-run/07bucket-access-control.jpg" loading="lazy" title="Make the bucket a uniform access control one, not fine grained access control" alt="Make the bucket a uniform access control one, not fine grained access control"><p>Then, keep the data protection policy as shown below, and click <code>Create</code> to create the bucket.</p><img class="center" src="/images/ollama-google-cloud-run/08bucket-create.jpg" loading="lazy" title="Keep the soft delete policy and create the bucket" alt="Keep the soft delete policy and create the bucket"><p>Next, it will ask you to confirm the access as below:</p><img class="center" src="/images/ollama-google-cloud-run/09bucket-create-confirm.jpg" loading="lazy" title="Confirm the bucket creation" alt="Confirm the bucket creation"><p>Click <code>Confirm</code>. It will take some time, but the bucket will be created, which will look like the below:</p><img class="center" src="/images/ollama-google-cloud-run/10bucket-created.jpg" loading="lazy" title="The bucket to store the Gemma 2:2b LLM and Ollama files has been created" alt="The bucket to store the Gemma 2:2b LLM and Ollama files has been created"><p>After the bucket is created, the next task is to deploy Ollama on Google Cloud Run.</p><h2 id="deploy-ollama-on-google-cloud-run" tabindex="-1">Deploy Ollama on Google Cloud Run <a class="direct-link" href="#deploy-ollama-on-google-cloud-run">#</a></h2><p>To deploy Ollama on Google Cloud Run, search for <code>cloud run</code> on the search bar:</p><img class="center" src="/images/ollama-google-cloud-run/11search-cloud-run.jpg" loading="lazy" title="Serach for cloud run on the GCP console search bar" alt="Serach for cloud run on the GCP console search bar"><p>Then click <code>Cloud Run</code> to go to the Cloud Run page. On that page, click on <code>Deploy Container</code> and then click on <code>Service</code> as shown below:</p><img class="center" src="/images/ollama-google-cloud-run/12add-cloud-run-service.jpg" loading="lazy" title="Add a cloud run service on the Cloud Run service listing page" alt="Add a cloud run service on the Cloud Run service listing page"><p>You will do all the important configurations on this page, so be careful. You will need to fill up the form as follows:</p><ul><li>In the <code>Container image URL</code> type in <code>ollama/ollama:0.5.7</code> - at the time of writing, <code>0.5.7</code> is the latest release and available as an image on <a href="https://hub.docker.com/r/ollama/ollama">DockerHub</a></li><li>In the service name, type in <code>ollama-gcs</code></li><li>Make sure the region is the same as the bucket, which is <code>us-central1</code></li><li>For now, select <code>Allow unauthenticated invocations</code>. This will make it accessible to anyone on the web, but we are doing it for the sake of this demo. In a real-life scenario, you would put it behind authentication.</li></ul><p>Till now, the form will look like the below:</p><img class="center" src="/images/ollama-google-cloud-run/13cloud-run-container-settings.jpg" loading="lazy" title="Point Cloud Run to use Ollama version 0.5.7 on Docker hub and use us-centra1 as the region" alt="Point Cloud Run to use Ollama version 0.5.7 on Docker hub and use us-centra1 as the region"><p>Then, for billing select <code>Instance-based</code> and keep the <code>Minimum number of instances</code> to 0. This makes it serverless. When no requests are coming in, no instances will be up and running, saving you money. After that, select the <code>Ingerss</code> to be <code>All</code> so that it allows traffic from the internet. At this point, your form will look as follows:</p><img class="center" src="/images/ollama-google-cloud-run/14cloud-run-billing.jpg" loading="lazy" title="Select instance based billing, set minimum instances to 0 and ingress to All" alt="Select instance based billing, set minimum instances to 0 and ingress to All"><p>Next, you will link the GCS bucket as a Cloud Run volume.</p><h3 id="wire-up-gsc-bucket-as-a-cloud-run-volume" tabindex="-1">Wire up GSC bucket as a Cloud Run Volume <a class="direct-link" href="#wire-up-gsc-bucket-as-a-cloud-run-volume">#</a></h3><p>This is an important part where you will link up the Google Cloud Storage (GCS) bucket created in the previous part as a volume for Google Cloud Run Containers. Click the volumes tab on the <code>Container(s), Volumes, Networking, Security</code> part:</p><img class="center" src="/images/ollama-google-cloud-run/15cloud-run-volumes-tab.jpg" loading="lazy" title="Click the Cloud Run - Volumes tab" alt="Click the Cloud Run - Volumes tab"><p>Then click <code>Add Volume</code> and select the <code>Volume type</code> as <code>Cloud Storage Bucket</code>. Let the name be <code>gcs-1</code>, and then for the <code>Bucket</code> click <code>Browse</code> and select the bucket you created in the previous step, which will be named something like <code>olllama-gemma2-2b-xyz</code>. Then click <code>Select</code>, at this point, the form will look like the below:</p><img class="center" src="/images/ollama-google-cloud-run/16cloud-run-volume-gcs.jpg" loading="lazy" title="Link the GCS bucket created in the previous step as volume named gcs-1" alt="Link the GCS bucket created in the previous step as volume named gcs-1"><p>Leave the <code>Read-only</code> checkbox unchecked, as the Cloud Run instances will write files to this bucket. Then click <code>Done</code>. It will say the bucket is <code>Not mounted</code> , which is fine.</p><img class="center" src="/images/ollama-google-cloud-run/17cloud-run-not-mounted.jpg" loading="lazy" title="Cloud Run GCS volume linked but not mounted" alt="Cloud Run GCS volume linked but not mounted"><p>After that, click the <code>Go to container(s) tab</code> or the <code>Container(s)</code> tab; on this tab, click the <code>Volume mounts</code> sub-tab, then click <code>Mount Volume</code>. Next, select the <code>Name-1</code> as <code>gcs-1</code> and on the <code>Mount path 1</code> type in <code>/root/.ollama</code> (don’t miss the <code>.</code> in front of ollama); this is where Ollama stores its models. So when the models are pulled (downloaded), they will be saved in this volume, which will also be saved in the bucket. It can be used in other instances as it is in the bucket.</p><img class="center" src="/images/ollama-google-cloud-run/18cloud-run-mount-volume.jpg" loading="lazy" title="Mount gcs-1 volume at /root/.ollama path" alt="Mount gcs-1 volume at /root/.ollama path"><p>Then click <code>Done</code>. You will set some environment variables for the container next. Click <code>Container: ollama-1</code> under the <code>Containers</code> tab to do this. Then click the <code>Variables and Secrets</code> sub-tab; after that, click <code>Add Variable</code>, and fill up the following in <code>Name 1</code> and <code>Value 1</code>:</p><ul><li><code>OLLAMA_HOST</code> with value <code>0.0.0.0:8080</code> – this will make Ollama run on port 8080, not the default port of <code>11434</code></li></ul><p>Similarly, add three more variables using the <code>Add Variable</code> button and fill up the following values:</p><ul><li><code>OLLAMA_DEBUG</code> with value <code>false</code> – this is self-explanatory</li><li><code>OLLAMA_KEEP_ALIVE</code> with value <code>-1</code> – it keeps the model weight on the GPU (if GPU is used)</li><li><code>GIN_MODE</code> with value <code>release</code> – is to remove any <a href="https://github.com/gin-gonic/gin">Go Gin</a> debug-related message. Ollama uses <a href="https://github.com/ollama/ollama/blob/main/server/routes.go#L43">Gin</a> under the hood,</li></ul><p>Your <code>Variables and Secrets</code> section will look like the below when you are done:</p><img class="center" src="/images/ollama-google-cloud-run/19cloud-run-variables.jpg" loading="lazy" title="Set all 4 needed variables of Ollama for Cloud Run" alt="Set all 4 needed variables of Ollama for Cloud Run"><p>After that, click the <code>Settings</code> tab and set the <code>Memory</code> to <code>32 GiB</code> and the <code>CPU</code> to <code>8</code>. You can request GPU access for your project by clicking the <code>GPU quota</code> link and filling out a form. Gemma 2 on Ollama will run (a bit slower, though) without the GPU.</p><img class="center" src="/images/ollama-google-cloud-run/20cloud-run-resources.jpg" loading="lazy" title="Set Port for Cloud Run to 8080 and allocate 32 GB of memory and 8 CPUs" alt="Set Port for Cloud Run to 8080 and allocate 32 GB of memory and 8 CPUs"><p>Your <code>Setting</code> section will look like the above when you are done editing it; after that, you can click <code>Done</code>. If you cannot allocate 32 GB of memory and 8 CPUs it might be because your account is new; you can reqeust a <a href="https://cloud.google.com/run/quotas#increase">quota increase</a>. Even with 512 MB of memory and 1 CPU, which you should have without a quota increase, you can run the <a href="https://ollama.com/library/smollm2:135m">smollm2:135m</a> at 135 million parameters; the model is 271 MB, which will fit in the 512 MB allocated memory.</p><p>Then, move on to the <code>Requests</code> section. Here, you can set the <code>Request timeout</code> to <code>300</code> seconds (5 minutes), the default value, and keep the<br><code>Maximum concurrent requests per instance</code> at <code>80</code>. Keep the <code>Minimum number of instances</code> as <code>0</code>; the only value you should change will be <code>Maximum number of instances</code>; keep it at 3 or 4 maximum. If someone attacks your service, it should timeout or send back a server error, then scale a lot, costing you loads of money. Your Cloud Run service creation form will look like the below:</p><img class="center" src="/images/ollama-google-cloud-run/21cloud-run-instances.jpg" loading="lazy" title="Set Port for Cloud Run timeout, max concurrency and min and max number of instances" alt="Set Port for Cloud Run timeout, max concurrency and min and max number of instances"><p>Then click <code>Create</code> and wait for some time as the <code>Ollama</code> image is 1.5 GB, it will take a bit to start. It will look like the following when it is deploying:</p><img class="center" src="/images/ollama-google-cloud-run/22cloud-run-creating.jpg" loading="lazy" title="Cloud run creating the Ollama service" alt="Cloud run creating the Ollama service"><p>It will look like the below after it is deployed successfully:</p><img class="center" src="/images/ollama-google-cloud-run/23cloud-run-created.jpg" loading="lazy" title="Cloud Run Service with Ollama created successfully and has a working URL now" alt="Cloud Run Service with Ollama created successfully and has a working URL now"><p>Click the service URL to see if it is working:</p><img class="center" src="/images/ollama-google-cloud-run/24cloud-run-ollama-up.jpg" loading="lazy" title="Ollama server is running on Cloud Run without any models" alt="Ollama server is running on Cloud Run without any models"><p>It will show <code>Ollama is running</code> as above if everything went fine. At this point, Ollama has no models to run any inference. So, in the next section, you will pull in and test Gemma 2:2b with Ollama using the Google Cloud Console. Gemma 2 will be the first model for this instance of Ollama.</p><h2 id="testing-gemma-2-with-ollama-on-google-cloud-console" tabindex="-1">Testing Gemma 2 with Ollama on Google Cloud Console <a class="direct-link" href="#testing-gemma-2-with-ollama-on-google-cloud-console">#</a></h2><p>To test Gemma2 (or any other <a href="https://ollama.com/search">model</a> that can run on Ollama), go back to the Google Cloud Console on the Cloud Run service page and click the Cloud Shell button (or hit G and then S on your keyboard). This will open the <a href="https://cloud.google.com/shell/docs/using-cloud-shell">Google Cloud Shell</a> terminal.</p><p>On the terminal, type <code>curl -fsSL https://ollama.com/install.sh | sh</code> to install Ollama; it has been taken from the Ollama Linux installation <a href="https://ollama.com/download/linux">page</a>. Let it execute, and it will show an output like the one below:</p><img class="center" src="/images/ollama-google-cloud-run/25ollama-install.jpg" loading="lazy" title="Install Ollama on Google Cloud console with the script from the official website" alt="Install Ollama on Google Cloud console with the script from the official website"><p>Then, copy the URL of your service, which will be something like <code>https://ollama-gcs-&lt;some-number-here&gt;.us-central1.run.app</code>. You can use the copy icon beside the URL. After that, execute the following command on your terminal:</p><pre class="language-bash"><code class="language-bash"><span class="token assign-left variable">OLLAMA_HOST</span><span class="token operator">=</span><span class="token operator">&lt;</span>copied-url<span class="token operator">></span> ollama run gemma2:2b</code></pre><p>It will download (pull) Gemma 2:2b and save it in the GCS bucket (a linked volume), and then you can chat with Gemma 2:2b. You can ask <code>who are you and Gemma will reply</code>:</p><img class="center" src="/images/ollama-google-cloud-run/26ollama-use-gemma2.jpg" loading="lazy" title="Use Gemma 2 2B params with Ollama installed on Google Cloud Console" alt="Use Gemma 2 2B params with Ollama installed on Google Cloud Console"><p>You can download/pull any other model Ollama supports and start using it. For example, you can download <code>llama3.3:70b</code> by Meta, <code>phi4:14b</code> by Microsoft, <code>deepseek-r1:8b</code> by <a href="https://api-docs.deepseek.com/news/news250120">DeepSeek</a> (which is getting very popular), or even <code>smollam2:135m</code>, which is only 271 MB in size compared to other models, which are GBs in size.</p><p>You can type <code>/bye</code> to get out of the ollama CLI. Now, as Gemma 2:2b is downloaded, you can also send a cURL command to test it out like the one below:</p><pre class="language-bash"><code class="language-bash"><span class="token function">curl</span> <span class="token parameter variable">-i</span> https://ollama-gcs-<span class="token operator">&lt;</span>some-number-here<span class="token operator">></span>.us-central1.run.app/api/generate <span class="token parameter variable">-d</span> <span class="token string">'{<br>  "model": "gemma2:2b",<br>  "prompt": "Why is the sky blue? Give the shortest answer possible",<br>  "stream": false<br>}'</span></code></pre><p>It will give an output as follows:</p><img class="center" src="/images/ollama-google-cloud-run/27ollama-curl.jpg" loading="lazy" title="Use Gemma 2 2B params with Ollama using a cURL POST on the generate API endpoint" alt="Use Gemma 2 2B params with Ollama using a cURL POST on the generate API endpoint"><p>If you go in the bucket and look at its contents, you will find Gemma 2 there:</p><img class="center" src="/images/ollama-google-cloud-run/28ollama-gemma-gcs.jpg" loading="lazy" title="Gemma 2 2B files in the Google Cloud Storage bucket created in the first step" alt="Gemma 2 2B files in the Google Cloud Storage bucket created in the first step"><p>Google Cloud Run makes it easy to run any LLM on Ollama. You can run Phi 4, Llama 3, or any other model; you must pull it and run your command or POST with curl. You can also use libraries like <a href="https://www.litellm.ai/">LiteLLM</a> to use the model in your apps using Ollama’s <a href="https://github.com/ollama/ollama/blob/main/docs/api.md">APIs</a>. Please explore Ollama more on your own. You can also use <a href="https://github.com/open-webui/open-webui">Open WebUI</a> to have a GUI on top of Oallma running Gemma 2 LLM.</p><h2 id="conclusion" tabindex="-1">Conclusion <a class="direct-link" href="#conclusion">#</a></h2><p>It is easy to run any LLM with Ollama on Google Cloud Run. Be careful of the access as Ollama APIs allow pulling models and even <a href="https://github.com/ollama/ollama/blob/main/docs/api.md#delete-a-model">deleting</a> them. With Cloud Run, you will only pay for the resources when you use it, which makes it ideal for experiments. I hope you learned something new from this post and keep experimenting.</p></div><div class="flex items-center justify-between gap-3 md:gap-4 flex-wrap md:flex-nowrap py-2 border-y border-lightbg mt-4"><div class="flex items-center justify-start md:gap-4 gap-2 flex-wrap w-2/3"><div class="flex justify-start items-center gap-3 md:gap-4"><img src="/images/favicons/favicon-32x32-pp.png" alt="Geshan Manandhar" class="w-10 h-10 rounded-full object-cover flex-shrink-0"> <span class="text-gray font-medium font-ui text-md md:text-xl uppercase tracking-wide text-start">Geshan Manandhar</span></div><time datetime="2025-01-20" data-updated="true"><time class="entry-date" datetime="2025-01-20"><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">20-Jan-2025 </span></time></time><span class="text-textColor font-ui font-medium text-md md:text-xl uppercase">11 MIN READ</span></div><button type="button" id="share-button-bottom" class="flex items-center justify-center w-8 h-8 md:w-9 md:h-9 rounded text-lightGray hover:border-gray-400 hover:bg-gray-50 transition-colors flex-shrink-0" aria-label="Share this post" onclick="toggleShareIconsBottom(); ga('send', 'event', 'share', 'clickShareOnPost');"><img src="/images/shareIcon.svg" alt="Share this post" class="w-6 h-6"></button></div><div id="share-icons-container-bottom" class="share-icons-bottom print:hidden hidden mx-auto" aria-label="Share this post"><div class="w-full flex items-center justify-center mx-auto gap-3"><span class="share-icons"><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on LinkedIn" onclick="ga('send', 'event', 'share', 'clickShareOnLinkedIn');"><span id="linkedin-share" class="text-[#0077B5]"><img src="/images/social-icons/linkedin.svg" alt="LinkedIn" class="sharing-common"> </span></a><a href="http://twitter.com/share?text=How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step] - &url=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Twitter" onclick="ga('send', 'event', 'share', 'clickShareOnTwitter');"><span id="twitter-share" class="text-[#1DA1F2]"><img src="/images/social-icons/twitter.svg" alt="Twitter" class="sharing-common"> </span></a><a href="http://www.facebook.com/sharer.php?u=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Facebook" onclick="ga('send', 'event', 'share', 'clickShareOnFacebook');"><span id="facebook-share" class="text-[#1877F2]"><img src="/images/social-icons/facebook.svg" alt="Facebook" class="sharing-common"> </span></a><a href="https://t.me/share/url?url=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Telegram" onclick="ga('send', 'event', 'share', 'clickShareOnTelegram');"><span id="telegram-share" class="text-[#0088cc]"><img src="/images/social-icons/telegram.svg" alt="Telegram" class="sharing-common"> </span></a><a href="https://api.whatsapp.com/send?text=https://geshan.com.np/blog/2025/01/ollama-google-cloud-run/" target="_blank" title="Share 'How to run (any) open LLM with Ollama on Google Cloud Run [Step-by-step]' on Whatsapp" onclick="ga('send', 'event', 'share', 'clickShareOnWhatsapp');"><span id="whatsapp-share" class="text-[#25d366]"><img src="/images/social-icons/whatsapp.svg" alt="WhatsApp" class="sharing-common"></span></a></span></div></div></article><div class="mt-3"><a href="/blog/categories/ai/" title="AI" class="background-lightbg mr-4 mb-2 inline-block mt-2 rounded border-2 bg-gray-100 font-semibold font-ui text-gray hover:text-gray-400 px-3 py-1 text-xl border-gray-300 cursor-pointer hover:border-gray-400">ai </a><a href="/blog/categories/gen-ai/" title="Gen AI" class="background-lightbg mr-4 mb-2 inline-block mt-2 rounded border-2 bg-gray-100 font-semibold font-ui text-gray hover:text-gray-400 px-3 py-1 text-xl border-gray-300 cursor-pointer hover:border-gray-400">gen ai </a><a href="/blog/categories/gcp/" title="GCP" class="background-lightbg mr-4 mb-2 inline-block mt-2 rounded border-2 bg-gray-100 font-semibold font-ui text-gray hover:text-gray-400 px-3 py-1 text-xl border-gray-300 cursor-pointer hover:border-gray-400">gcp</a></div><section class="md:w-full mx-auto mt-4"><h3 class="comments font-heading">Comments</h3><div id="disqus_thread"></div><button id="disqus_trigger" class="font-ui text-blackText hover:border-darkAvocado border-blacktext hover:shadow-lg border-2 transition ease-in-out delay-100 px-3 py-2 pt-2 mt-2 rounded-md text-center block h-auto text-xl" onclick="load_disqus()">Post a Comment</button><div id="disqus_thread" aria-live="polite"></div></section></div></div><section class="md:w-full mx-auto mt-4 bg-lightAvocado p-4 rounded-lg pb-8"><div class="max-w-6xl mx-auto md:py-12 px-4"><h2 class="text-4xl text-darkAvocado font-heading font-regular flex-shrink-0 py-8 tracking-normal leading-[105%] md:leading-[105%]"><span class="text-lightGray italic">Related</span> <span class="text-blackText">Blogs</span></h2><div class="grid grid-cols-1 md:grid-cols-2 gap-8"><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2025/11/google-ai-studio-build/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to build your own resume reviewer with Google AI Studio in minutes</a> <time class="font-medium text-xl text-textColor uppercase font-ui">14-Nov-2025 &nbsp;&nbsp;&nbsp; 9 min read</time><p class="text-xl text-gray font-ui">Learn how to build your own resume reviewer with Google AI Studio in minutes and deploy it on Google Cloud Run.</p></div><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2025/06/gemma3-on-cloud-run/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to run Gemma 3 on Google Cloud Run, the easiest way with AI Studio</a> <time class="font-medium text-xl text-textColor uppercase font-ui">08-Jun-2025 &nbsp;&nbsp;&nbsp; 7 min read</time><p class="text-xl text-gray font-ui">Learn how to deploy Gemma 3 on Google Cloud Run using Google AI Studio, also understand the magic behind the process.</p></div><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2025/05/google-ai-studio-apps/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">Google AI Studio: How to go from a prompt to a geo-location guessing app in minutes</a> <time class="font-medium text-xl text-textColor uppercase font-ui">22-May-2025 &nbsp;&nbsp;&nbsp; 10 min read</time><p class="text-xl text-gray font-ui">Learn how to generate, create and deploy a geo-location guessing app using Google AI Studio and run it on Google Cloud Run step by step.</p></div><div class="py-4 border-b border-avocado pb-4 flex flex-col gap-2 font-ui"><a href="/blog/2025/02/ollama-docker-compose/" class="font-semibold font-ui text-gray text-xl md:text-2xl tracking-[-0.01em] leading-[105%] md:leading-[105%]">How to use Ollama and Open WebUI with Docker Compose [Part 4]</a> <time class="font-medium text-xl text-textColor uppercase font-ui">11-Feb-2025 &nbsp;&nbsp;&nbsp; 11 min read</time><p class="text-xl text-gray font-ui">Learn how to use Ollama and Open WebUI inside Docker with Docker compose to run any open LLM and create your own mini ChatGPT.</p></div></div></div></section><section class="bg-avocado md:py-0 py-12 px-4"><div class="max-w-6xl mx-auto"><div class="md:hidden"><h2 class="mb-4 text-3xl font-heading font-regular text-textColor break-words tracking-[-0.01em] leading-[105%] md:leading-[105%]"><span class="text-textColor italic">Stay</span><span class="text-blackText"> Connected</span></h2><p class="text-base text-blackText font-body font-regular mb-6">Follow me on LinkedIn for new posts, engineering insights, and tech takes — straight from the trenches.</p><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="inline-block bg-darkAvocado text-base text-white px-6 py-3 rounded-lg font-body font-regular hover:opacity-90 transition-opacity w-full text-center">Follow on LinkedIn &nbsp;→</a></div><div class="hidden md:grid lg:hidden grid-cols-3 gap-8 items-center"><div class="z-10 col-span-2"><h2 class="mb-4 text-2xl md:text-4xl font-heading font-regular text-textColor break-words tracking-[-0.01em] leading-[105%] md:leading-[105%]"><span class="text-textColor italic">Stay</span><span class="text-blackText"> Connected</span></h2><p class="text-xl text-blackText font-body font-regular mb-6">Follow me on LinkedIn for new posts, engineering insights, and tech takes — straight from the trenches.</p><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="inline-block bg-darkAvocado text-xl text-white px-6 py-3 rounded-lg font-body font-regular hover:opacity-90 transition-opacity">Follow on LinkedIn &nbsp;→</a></div><div class="flex items-center justify-end col-span-1"><img class="w-32 h-auto" src="/images/theme/new_logo.svg" alt="Geshan"></div></div><div class="hidden lg:grid grid-cols-2 gap-8 lg:gap-12 items-center justify-between h-full"><div class="z-10"><h2 class="mb-4 text-2xl md:text-4xl font-heading font-regular text-textColor break-words tracking-[-0.01em] leading-[105%] md:leading-[105%]"><span class="text-textColor italic">Stay</span><span class="text-blackText"> Connected</span></h2><p class="text-xl text-blackText font-body font-regular mb-6">Follow me on LinkedIn for new posts, engineering insights, and tech takes — straight from the trenches.</p><p class="text-xl text-blackText font-body font-regular mb-6">A big thank you for supporting this ad. free, unobstructive (no overlays, no pop-ups) blog.</p></div><div class="flex items-center gap-12 w-full md:w-auto justify-end self-end"><img class="w-16 md:w-32 h-auto" src="/images/theme/new_logo.svg" alt="Geshan"> <a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer" class="inline-block bg-darkAvocado text-xl text-white px-6 py-3 rounded-lg font-body font-regular hover:opacity-90 transition-opacity w-full md:w-auto text-center md:text-left">Follow on LinkedIn &nbsp;→</a></div></div></div></section></div></div></div></main><footer role="contentinfo"><footer class="bg-avocado sm:px-4"><div class="max-w-6xl mx-auto flex flex-col md:flex-row sm:flex-col justify-between gap-2 items-center sm:items-center md:items-center py-10 font-nav text-lightGray text-base font-regular"><div class="pb-0 sm:pb-2 text-gray"><span class="pr-4">Copyright © 2026 Geshan Manandhar.</span></div><div class="pb-0 sm:pb-2"><ul class="flex"><li class="hover:text-gray-300 text-lg pr-4 cursor-pointer text-gray"><a href="https://www.linkedin.com/in/geshan" target="_blank" rel="noopener noreferrer nofollow" class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 1000 1000"><path fill="currentColor" d="M1000 267q0 112-78 188L747 631q-78 78-189 78q-97 0-171-63l115-115q26 17 56 17q44 0 75-31l175-176q31-29 31-74q0-44-30.5-74.5T734 162q-25 0-49.5 12T652 208H414L546 79Q626 1 734 1q110 0 188 78t78 188zm-387 89L498 471q-26-17-56-17q-44 0-75 31L192 661q-31 29-31 74q0 44 30.5 74.5T266 840q25 0 49.5-12t32.5-34h238L454 923q-80 78-188 78q-110 0-188-78T0 735q0-112 78-188l175-176q78-78 189-78q97 0 171 63z"/></svg> LinkedIn</a></li><li class="hover:text-gray-300 text-lg pr-4 cursor-pointer text-gray"><a href="https://www.twitter.com/geshan" target="_blank" rel="noopener noreferrer nofollow" class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 1000 1000"><path fill="currentColor" d="M1000 267q0 112-78 188L747 631q-78 78-189 78q-97 0-171-63l115-115q26 17 56 17q44 0 75-31l175-176q31-29 31-74q0-44-30.5-74.5T734 162q-25 0-49.5 12T652 208H414L546 79Q626 1 734 1q110 0 188 78t78 188zm-387 89L498 471q-26-17-56-17q-44 0-75 31L192 661q-31 29-31 74q0 44 30.5 74.5T266 840q25 0 49.5-12t32.5-34h238L454 923q-80 78-188 78q-110 0-188-78T0 735q0-112 78-188l175-176q78-78 189-78q97 0 171 63z"/></svg> Twitter</a></li><li class="hover:text-gray-300 text-lg pr-4 cursor-pointer text-gray"><a href="https://github.com/geshan" target="_blank" rel="noopener noreferrer nofollow" class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 1000 1000"><path fill="currentColor" d="M1000 267q0 112-78 188L747 631q-78 78-189 78q-97 0-171-63l115-115q26 17 56 17q44 0 75-31l175-176q31-29 31-74q0-44-30.5-74.5T734 162q-25 0-49.5 12T652 208H414L546 79Q626 1 734 1q110 0 188 78t78 188zm-387 89L498 471q-26-17-56-17q-44 0-75 31L192 661q-31 29-31 74q0 44 30.5 74.5T266 840q25 0 49.5-12t32.5-34h238L454 923q-80 78-188 78q-110 0-188-78T0 735q0-112 78-188l175-176q78-78 189-78q97 0 171 63z"/></svg> Github</a></li></ul></div></div></footer></footer><script src="/js/all.min.js" defer="defer"></script></body></html>